####
## Source descriptions:
##

#Tail a log file
#<source>
#	 type tail
#	 path /fluent/log/file.log
#	 #file that stores the position of the last sent message
#	 pos_file /fluentd/log/file.log.pos
#	 #tag to be set to each outgoing message
#	 tag "#{ENV['FLUENTD_TAIL_TAG']}"
#	 read_from_head true
#
#	 #since logs may contain messages that span multiple lines, we can treat
#   #multi-line messages as a single message by identifying the timestamp that
#   #is the prefix for every log entry
#	 format multiline
#	 format_firstline /\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{3}/
#	 #we go with the most generic pattern where we know a message will have
#   #a timestamp in front of it, the rest is just stored in the field 'message'
#	 format1 /(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{3}) (?<message>(.|\s)*)/
#</source>

<source>
  @type tail
  path /fluent/log/file.log
  pos_file /fluentd/log/file.log.pos
  tag "#{ENV['FLUENTD_TAIL_TAG']}"
  read_from_head true
  <parse>
    @type multiline
    format_firstline /\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{3}/
    format1 /(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{3}) (?<message>(.|\s)*)/
  </parse>
</source>


####
## Filter descriptions:
##
#All messages that have been identified to contain the standard message
#structure are parsed to extract individual fields
<filter shipper.log.parse>
	@type parser
	key_name message
	format / * (.*method:) (?<method>[^;]*) *(.*Object:) (?<object>[^;]*) *(.*Key:) (?<objectkey>[^;]*) *(.*MessageID:) (?<messageID>[^;]*) *(.*CorrelationID:) (?<correlationID>[^;]*).*/
	reserve_data yes
</filter>

#Add Source project name to all messages for easier filtering in kibana
<filter **>
	@type record_transformer
	<record>
		sourceProject "#{ENV['FLUENTD_SOURCEPROJECT']}"
	</record>
</filter>

####
## Output descriptions:
##

##If the message contains a CorrelationID in message we change the tag to
##identify it so it will match the filter
#<match default.**>
#	type rewrite_tag_filter
#  #example: Based on regex matches you can re-tag messages and then process
#  #them separately.
#	rewriterule1 message \bCorrelationID\b shipper.log.parse
#	#all other messages are re-tagged to be discarded
#	rewriterule2 message .* shipper.log.message
#</match>

<match shipper.**>
  @id   docker_fluentd_shipper
  @type forward

  transport tls
  tls_cert_path /fluentd/certs/ca_cert.pem

  ### There are some options for detailed configuration....
  # tls_version              TLSv1_2  # TLS v1.2 (or TLSv1_1)
  # tls_insecure_mode          false  # skip all certificate checks if true
  # tls_allow_self_signed_cert false
  # tls_verify_hostname         true  # verify FQDN in certificates, with SNI

  <server>
    host "#{ENV['FLUENTD_AGGREGATOR_ADDR']}"
    port "#{ENV['FLUENTD_AGGREGATOR_PORT']}"
  </server>
</match>


